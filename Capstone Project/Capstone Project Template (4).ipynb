{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Weather Temperatures Vs. I-94 Immigration!\n",
    "\n",
    "## Data Engineering Capstone Project\n",
    "* By Abdullah Alqithmi\n",
    "### Project Summary\n",
    "The objective of the project is to create pipelines that pull data from different resources and insert their data into a DB model that is designed for analytical purposes. To be specific, the designed model  \n",
    "will help to study the relation between weather temperatures & I-94 immigration behaviors.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 1: Scope the Project and Gather Data\n",
    "\n",
    "### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "### Describe and Gather Data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### I-94 Immigration Data\n",
    "\n",
    "**Form I-94**, the Arrival-Departure Record Card, is a form used by U.S. Customs and Border Protection (CBP) intended to keep track of the arrival and departure to/from the United States of people who are not United States citizens or lawful permanent residents \n",
    "\n",
    "*This data comes from the **US National Tourism and Trade Office**. IT will be used as the **main dataset** for this project*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "df = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "1      NaN   ...           Y      NaN   1991.0       D/S      M    NaN   \n",
       "2  20691.0   ...         NaN        M   1961.0  09302016      M    NaN   \n",
       "3  20567.0   ...         NaN        M   1988.0  09302016    NaN    NaN   \n",
       "4  20567.0   ...         NaN        M   2012.0  09302016    NaN    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.897628e+09    NaN       B2  \n",
       "1     NaN  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### World Temperature Data\n",
    "\n",
    "The data is from a newer compilation put together by the **Berkeley Earth**, which is affiliated with Lawrence Berkeley National Laboratory. The Berkeley Earth Surface Temperature Study combines 1.6 billion temperature reports from 16 pre-existing archives. It is nicely packaged and allows for slicing into interesting subsets (for example by country). They publish the source data and the code for the transformations they applied. They also use methods that allow weather observations from shorter time series to be included, meaning fewer observations need to be thrown away.\n",
    "\n",
    "*This dataset came from **Kaggle**.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "temName = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "dt = pd.read_csv(temName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068                          1.737  Århus   \n",
       "1  1743-12-01                 NaN                            NaN  Århus   \n",
       "2  1744-01-01                 NaN                            NaN  Århus   \n",
       "3  1744-02-01                 NaN                            NaN  Århus   \n",
       "4  1744-03-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### U.S. City Demographic Data\n",
    "\n",
    "This dataset contains information about the demographics of all US cities and census-designated places with a population greater or equal to 65,000. The data came from the US Census Bureau's 2015 American Community Survey.\n",
    "\n",
    "*This data comes from **OpenSoft.** *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "usName = 'us-cities-demographics.csv'\n",
    "du = pd.read_csv(usName, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "du.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Airport Code Data\n",
    "\n",
    "This is a simple table of airport codes and corresponding cities. \n",
    "\n",
    "The airport codes may refer to either IATA airport code, a three-letter code which is used in passenger reservation, ticketing and baggage-handling systems, or the ICAO airport code which is a four letter code used by ATC systems and for airports that do not have an IATA airport code.\n",
    "\n",
    "*This data comes from **Datahub**.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "airName = 'airport-codes_csv.csv'\n",
    "da = pd.read_csv(airName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Temperature Dataset Shape:  (8599212, 7)\n",
      "U.S. City Demographic Dataset Shape:  (2891, 12)\n",
      "Airport Code Dataset Shape:  (55075, 12)\n"
     ]
    }
   ],
   "source": [
    "#check the dataset shape\n",
    "print('I-94 Immigration Dataset Shape: ',df.shape)\n",
    "\n",
    "print('World Temperature Dataset Shape: ',dt.shape)\n",
    "\n",
    "print('U.S. City Demographic Dataset Shape: ',du.shape)\n",
    "\n",
    "print('Airport Code Dataset Shape: ',da.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-94 Immigration Dataset null values: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cicid        0.00\n",
       "i94yr        0.00\n",
       "i94mon       0.00\n",
       "i94cit       0.00\n",
       "i94res       0.00\n",
       "i94port      0.00\n",
       "arrdate      0.00\n",
       "i94mode      0.01\n",
       "i94addr      4.92\n",
       "depdate      4.60\n",
       "i94bir       0.03\n",
       "i94visa      0.00\n",
       "count        0.00\n",
       "dtadfile     0.00\n",
       "visapost    60.76\n",
       "occup       99.74\n",
       "entdepa      0.01\n",
       "entdepd      4.47\n",
       "entdepu     99.99\n",
       "matflag      4.47\n",
       "biryear      0.03\n",
       "dtaddto      0.02\n",
       "gender      13.38\n",
       "insnum      96.33\n",
       "airline      2.70\n",
       "admnum       0.00\n",
       "fltno        0.63\n",
       "visatype     0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the dataset null values\n",
    "print('I-94 Immigration Dataset null values: ')\n",
    "((df.isnull() | df.isna()).sum() * 100 / df.index.size).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Temperature Dataset null values: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dt                               0.00\n",
       "AverageTemperature               4.23\n",
       "AverageTemperatureUncertainty    4.23\n",
       "City                             0.00\n",
       "Country                          0.00\n",
       "Latitude                         0.00\n",
       "Longitude                        0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the dataset null values\n",
    "print('World Temperature Dataset null values: ')\n",
    "((dt.isnull() | dt.isna()).sum() * 100 / dt.index.size).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U.S. City Demographic Dataset null values: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "City                      0.00\n",
       "State                     0.00\n",
       "Median Age                0.00\n",
       "Male Population           0.10\n",
       "Female Population         0.10\n",
       "Total Population          0.00\n",
       "Number of Veterans        0.45\n",
       "Foreign-born              0.45\n",
       "Average Household Size    0.55\n",
       "State Code                0.00\n",
       "Race                      0.00\n",
       "Count                     0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the dataset null values\n",
    "print('U.S. City Demographic Dataset null values: ')\n",
    "((du.isnull() | du.isna()).sum() * 100 / du.index.size).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airport Code Dataset null values: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ident            0.00\n",
       "type             0.00\n",
       "name             0.00\n",
       "elevation_ft    12.72\n",
       "continent       50.33\n",
       "iso_country      0.45\n",
       "iso_region       0.00\n",
       "municipality    10.31\n",
       "gps_code        25.50\n",
       "iata_code       83.32\n",
       "local_code      47.91\n",
       "coordinates      0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the dataset null values\n",
    "print('Airport Code Dataset null values: ')\n",
    "((da.isnull() | da.isna()).sum() * 100 / da.index.size).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Cleaning Steps\n",
    "During the cleaning steps, we did the following\n",
    "* Removing Null values\n",
    "* Removing Duplicated values\n",
    "* Adding/removing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Creating Spark session\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### I-94 Immigration Data *Cleaning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Reading I-94 Immigration Dataset into Spark\n",
    "df_imm =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')\n",
    "print('I-94 Immigration Dataset before Cleaning contains:',df_imm.count(),'rows' ,' || ',len(df_imm.columns), 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "compil = re.compile(r'\\'(.*)\\'.*\\'(.*)\\'')\n",
    "I94_valid_labels = {}\n",
    "with open('I94_valid_labels.txt') as f:\n",
    "     for data in f:\n",
    "         match = compil.search(data)\n",
    "         I94_valid_labels[match[1]]=[match[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Clean immigration data\n",
    "def I94DatasetClenser(file):\n",
    "\n",
    "    '''    \n",
    "    Input: I-94 Immigration dataset file's path\n",
    "    Output:  I-94 Immigration data as Spark Dataframe\n",
    "    '''    \n",
    "    df_i94 = spark.read.format('com.github.saurfang.sas.spark').load(file)\n",
    "    \n",
    "    # Filter out entries where i94port is invalid\n",
    "    df_i94 = df_i94.filter(df_i94.i94port.isin(list(I94_valid_labels.keys())))\n",
    "\n",
    "    return df_i94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "I94_file = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat' \n",
    "df_immCleaned = I94DatasetClenser(I94_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#drop duplicated value for id\n",
    "df_immCleaned=df_immCleaned.dropDuplicates(['cicid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Removing columns with high percentage of null values\n",
    "columns_to_drop = ['entdepu','occup','insnum'] \n",
    "df_immCleaned = df_immCleaned.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-94 Immigration Dataset After Cleaning contains: 3088544 rows  ||  25 columns\n"
     ]
    }
   ],
   "source": [
    "print('I-94 Immigration Dataset After Cleaning contains:',df_immCleaned.count(),'rows' ,' || ',len(df_immCleaned.columns), 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### World Temperature Dataset *Cleaning*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Reading World Temperature Dataset into Spark\n",
    "dt_temp=spark.read.format(\"csv\").option(\"header\", \"true\").load(\"../../data2/GlobalLandTemperaturesByCity.csv\")\n",
    "print('World Temperature Dataset before Cleaning contains:',dt_temp.count(),'rows' ,' || ',len(dt_temp.columns), 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Removing duplicate values\n",
    "dt_temp=dt_temp.dropDuplicates(['dt','Country','City'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Removing NaN values\n",
    "dt_temp=dt_temp.filter(dt_temp.AverageTemperature != 'NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World Temperature Dataset after Cleaning contains: 8190131 rows  ||  7 columns\n"
     ]
    }
   ],
   "source": [
    "# check dataset size after Cleaning\n",
    "print('World Temperature Dataset after Cleaning contains:',dt_temp.count(),'rows' ,' || ',len(dt_temp.columns), 'columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Adding Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "@udf()\n",
    "def AddColumn(city):\n",
    "    '''\n",
    "    Input: The column name \n",
    "    Output: The equivalent I-94 Port \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    for i in I94_valid_labels:\n",
    "        if city.lower() in I94_valid_labels[i][0].lower():\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+-----------------------------+-------------------+--------------+--------+---------+-------+\n",
      "|        dt|AverageTemperature|AverageTemperatureUncertainty|               City|       Country|Latitude|Longitude|i94port|\n",
      "+----------+------------------+-----------------------------+-------------------+--------------+--------+---------+-------+\n",
      "|1743-11-01|            12.686|                        2.051|             Durrës|       Albania|  40.99N|   19.17E|   null|\n",
      "|1743-11-01| 5.167000000000001|                        1.774|            Bergamo|         Italy|  45.81N|   10.38E|   null|\n",
      "|1743-11-01|             3.765|                        1.893|          Stavanger|        Norway|  58.66N|    6.15E|   null|\n",
      "|1743-11-01|             6.678|                         1.81|          Stockport|United Kingdom|  53.84N|    1.36W|   null|\n",
      "|1743-11-01| 8.129999999999999|                        2.245|            Atlanta| United States|  34.56N|   83.68W|    ATL|\n",
      "|1744-04-01|            -0.211|                        3.715|               Oulu|       Finland|  65.09N|   24.89E|   null|\n",
      "|1744-04-01|11.684000000000001|                        2.377|             Maykop|        Russia|  44.20N|   40.25E|   null|\n",
      "|1744-04-01|            17.657|                        2.096|           Columbia| United States|  34.56N|   81.73W|    CAE|\n",
      "|1744-04-01|            15.356|                        2.327|         Evansville| United States|  37.78N|   87.46W|   null|\n",
      "|1744-05-01|            11.034|                        1.307|             Erfurt|       Germany|  50.63N|   11.41E|   null|\n",
      "|1744-05-01|12.074000000000002|                        1.837|           Ploiesti|       Romania|  45.81N|   26.54E|   null|\n",
      "|1744-06-01|            12.657|                        1.364|          Groningen|   Netherlands|  53.84N|    6.82E|   null|\n",
      "|1744-06-01|            15.233|           1.3319999999999999|Gorzow Wielkopolski|        Poland|  52.24N|   15.77E|   null|\n",
      "|1744-06-01|             15.77|                        2.249|            Sarapul|        Russia|  57.05N|   54.59E|   null|\n",
      "|1744-06-01|15.263000000000002|                        1.831|          Yaroslavl|        Russia|  57.05N|   39.84E|   null|\n",
      "|1744-06-01|            17.756|                        2.051|           Alcorcón|         Spain|  40.99N|    4.26W|   null|\n",
      "|1744-07-01|            16.287|           1.4869999999999999|              Mainz|       Germany|  50.63N|    8.87E|   null|\n",
      "|1744-07-01|            19.401|           1.5659999999999998|        Cluj Napoca|       Romania|  47.42N|   22.50E|   null|\n",
      "|1744-09-01|            13.581|                         1.51|             Prague|Czech Republic|  50.63N|   13.94E|   null|\n",
      "|1744-09-01|            13.493|                        1.452|          Paderborn|       Germany|  52.24N|    7.88E|   null|\n",
      "+----------+------------------+-----------------------------+-------------------+--------------+--------+---------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_temp = dt_temp.withColumn(\"i94port\", AddColumn(dt_temp.City))\n",
    "dt_temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove Null values from iport94\n",
    "dt_temp = dt_temp.filter(dt_temp.i94port != 'null')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "The chosen model is consists of a fact table with 2 dimension tables. For the 2 dimension tables, we will its data from both I-94 immigration and temperature datasets, and it will be partitioned by the city column. To create the fact table, we used a join based on the city.\n",
    "___\n",
    "This model or schema will be used by users to analyze the data and answer questions regarding the relation between the weather temperatures and the destination (cities) that been chosen by the I-94 applicants  \n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<img src=\"Model.jpg\" alt=\"ER\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Creating a view to be used for the fact table\n",
    "df_immCleaned.createOrReplaceTempView(\"DiEventsView\")\n",
    "dt_temp.createOrReplaceTempView(\"DiCityTemperatureView\")\n",
    "\n",
    "\n",
    "# Creating the I94_Immigration table *fact table*\n",
    "I94_Immigration = spark.sql(\n",
    "    '''\n",
    "SELECT\n",
    "       DiEventsView.i94port as CityCode,\n",
    "       DiEventsView.arrdate as ArrivalDate,\n",
    "       DiEventsView.depdate as DepartureDate,\n",
    "       DiEventsView.i94visa as VisaCode,\n",
    "       DiEventsView.i94yr as year,\n",
    "       DiEventsView.i94mon as month,\n",
    "       DiEventsView.i94cit as city,\n",
    "       DiCityTemperatureView.AverageTemperature as Temperature,\n",
    "       DiCityTemperatureView.Latitude,\n",
    "       DiCityTemperatureView.Longitude\n",
    "FROM\n",
    "DiEventsView\n",
    "JOIN DiCityTemperatureView ON (DiEventsView.i94port = DiCityTemperatureView.i94port)\n",
    "    '''\n",
    ")\n",
    "\n",
    "# insert into I94_Immigration table\n",
    "I94_Immigration.write.mode(\"append\").partitionBy(\"CityCode\").parquet(\"/results/I94_Immigration.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Creating the DiEvents table *dimension table* \n",
    "DiEvents = df_immCleaned.select([\"i94yr\", \"i94mon\", \"i94cit\", \"i94port\", \"arrdate\", \"i94mode\", \"depdate\", \"i94visa\"])\n",
    "\n",
    "# insert into DiEvents table\n",
    "DiEvents.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/results/DiEvents.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Creating the temp_table table *dimension table* \n",
    "DiCityTemperature = dt_temp.select([\"AverageTemperature\", \"City\", \"Country\", \"Latitude\", \"Longitude\", \"i94port\"])\n",
    "\n",
    "# insert into temp_table table\n",
    "DiCityTemperature.write.mode(\"append\").partitionBy(\"i94port\").parquet(\"/results/DiCityTemperature.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.2 Data Quality Checks\n",
    "\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Quality Check 1\n",
    "#check the records number\n",
    "def dataquality_checks(df, table_name):\n",
    "   '''\n",
    "    Input:  Spark Dataframe\n",
    "    Output: The results of the quality check\n",
    "    '''\n",
    "    count = df.count()\n",
    "\n",
    "    if count == 0:\n",
    "        print(f\"Data quality failed. {table_name} has zero records!\")\n",
    "    else:\n",
    "        print(f\"Data quality passed. {table_name} has {count:,} records.\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Quality Check 1\n",
    "#check the records number by call the predefined function  \n",
    "table_dfs = {\n",
    "    'I94_Immigration': I94_Immigration,\n",
    "    'DiEvents': DiEvents\n",
    "    'DiCityTemperature': DiCityTemperature,\n",
    "}\n",
    "\n",
    "for table_name, table_df in table_dfs.items():\n",
    "    dataquality_checks(table_df, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Quality Check 2\n",
    "#check the number of distinct records \n",
    "def dataquality_checks2(df, table_name):\n",
    "   '''\n",
    "    Input:  Spark Dataframe\n",
    "    Output: The results of the quality check\n",
    "    '''\n",
    "    count = df.select(\"*\").distinct().count()\n",
    "\n",
    "    if count == 1:\n",
    "        print(f\"Data quality failed. {table_name} has Insufficient number of distinct records!\")\n",
    "    else:\n",
    "        print(f\"Data quality passed. {table_name} has {count:,} distinct records.\")\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Quality Check 2\n",
    "#check the number of distinct records \n",
    "table_dfs = {\n",
    "    'I94_Immigration': I94_Immigration,\n",
    "    'DiEvents': DiEvents\n",
    "    'DiCityTemperature': DiCityTemperature,\n",
    "}\n",
    "\n",
    "for table_name, table_df in table_dfs.items():\n",
    "    dataquality_checks2(table_df, table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4.3 Data dictionary \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### I-94 Immigration Dataset *Dictionary*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Column Name | Description |\n",
    "| :--- | :--- |\n",
    "| CICID* | ID that uniquely identify one record in the dataset |\n",
    "| I94YR | 4 digit year |\n",
    "| I94MON | Numeric month |\n",
    "| I94CIT | 3 digit code of origin city |\n",
    "| I94RES | 3 digit code of residence country |\n",
    "| I94PORT | Code of destination USA city |\n",
    "| ARRDATE | Arrival date|\n",
    "| I94MODE | Travel type code |\n",
    "| I94ADDR | Destination State |\n",
    "| DEPDATE | Departure date |\n",
    "| I94BIR | Age of Respondent in Years |\n",
    "| I94VISA | Visa codes collapsed into three categories |\n",
    "| COUNT | Used for summary statistics |\n",
    "| DTADFILE | Character Date Field |\n",
    "| VISAPOST | The department that the Visa was issued from |\n",
    "| OCCUP | Occupation that will be performed in U.S. |\n",
    "| ENTDEPA | Arrival Flag - admitted or paroled into the U.S. |\n",
    "| ENTDEPD | Departure Flag - Departed, lost I-94 or is deceased |\n",
    "| ENTDEPU | Update Flag - Either apprehended, overstayed, adjusted to perm residence |\n",
    "| MATFLAG | Match flag - Match of arrival and departure records |\n",
    "| BIRYEAR | 4 digit year of birth |\n",
    "| DTADDTO | Character Date Field - Date to which admitted to U.S. (allowed to stay until) |\n",
    "| GENDER | Gender |\n",
    "| INSNUM | INS number |\n",
    "| AIRLINE | Airline used to arrive in U.S. |\n",
    "| ADMNUM | Admission number |\n",
    "| FLTNO | Flight number of Airline used to arrive in U.S. |\n",
    "| VISATYPE | Class of admission legally admitting the non-immigrant to temporarily stay in U.S. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### World Temperature Dataset *Dictionary*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Column Name | Description |\n",
    "| :--- | :--- |\n",
    "| dt | Date |\n",
    "| AverageTemperature | The Average temperature of the city |\n",
    "| City | The City Name |\n",
    "| Country | The Country Name |\n",
    "| Latitude | Latitude |\n",
    "| Longitude | Longitude |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### U.S. City Demographic Dataset *Dictionary*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Column Name | Description |\n",
    "| :--- | :--- |\n",
    "| City | The city name |\n",
    "| State | The state name |\n",
    "| Median Age | The median of the age |\n",
    "| Male Population | Male population |\n",
    "| Female Population | Female population |\n",
    "| Total Population | Total population |\n",
    "| Number of Veterans | Number of veterans in each city |\n",
    "| Foreign-born | Number of Foreign the in the city |\n",
    "| Average Household Size | Average size of the houses in the city |\n",
    "| State Code | Code of the state |\n",
    "| Race | Race type |\n",
    "| Count | Count of race |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Airport Code Dataset *Dictionary*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Column Name | Description |\n",
    "| :--- | :--- |\n",
    "| ident | Identifier |\n",
    "| type | Type of the airport |\n",
    "| name | Airport Name |\n",
    "| elevation_ft | The altitude of the airport |\n",
    "| continent | Continent |\n",
    "| iso_country | ISO code of the airport country |\n",
    "| iso_region | ISO code for the airport region |\n",
    "| municipality | The airport city |\n",
    "| gps_code | GPS code of the airport |\n",
    "| iata_code | IATA code of the airport |\n",
    "| local_code | The code of the airport |\n",
    "| coordinates | The coordinates of the airport |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Step 5: Complete Project Write Up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "\n",
    "We used Apache spark for several reasons:\n",
    "<ol>\n",
    "    <li>Lighting-fast processing speed</li>\n",
    "    <li>Ease of use</li>\n",
    "    <li>It offers support for sophisticated analytics</li>\n",
    "    <li>Support a variety of file formats</li>\n",
    "    <li>It is flexible</li>\n",
    "    <li>Active and expanding community</li>\n",
    "</ol>  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Propose how often the data should be updated and why.\n",
    "\n",
    "We propose to update the data once a month, so each month, we would load the data as a single batch. That is because of one of our main sources of data (I-94 data) is updated monthly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### The Appropriate Approach to The Following Scenarios:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<ol>\n",
    "  <li>The data was increased by 100x.</li>\n",
    "</ol>    \n",
    "    We can add more nodes to the cluster to increase its capabilities, and instead of loading the datasets as a single batch, we can load the data incrementally.\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<ol start ='2'>\n",
    "\n",
    "  <li>The data populates a dashboard that must be updated on a daily basis by 7am every day.</li>\n",
    "\n",
    "</ol>\n",
    "\n",
    "We can use Apache Airflow to create pipelines with a schedule, or we can use Informatica Power Center, which is another famous ETL tool\n",
    "<hr />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<ol start ='3'>\n",
    "\n",
    "  <li>The database needed to be accessed by 100+ people.</li>\n",
    "</ol>\n",
    "\n",
    "Adding more nodes to the cluster still can handle this scenario also. On the other hand, we can use Amazon Redshift instead of our current DB as another option.\n",
    "\n",
    "<hr />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
